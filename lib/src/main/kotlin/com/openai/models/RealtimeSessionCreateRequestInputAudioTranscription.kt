/**
 *
 * Please note:
 * This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * Do not edit this file manually.
 *
 */

@file:Suppress(
    "ArrayInDataClass",
    "EnumEntryName",
    "RemoveRedundantQualifierName",
    "UnusedImport"
)

package com.openai.models


import com.squareup.moshi.Json
import com.squareup.moshi.JsonClass

/**
 * Configuration for input audio transcription, defaults to off and can be  set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs  asynchronously through [OpenAI Whisper transcription](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as rough guidance rather than the representation understood by the model. The client can optionally set the language and prompt for transcription, these fields will be passed to the Whisper API. 
 *
 * @param model The model to use for transcription, `whisper-1` is the only currently  supported model. 
 * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency. 
 * @param prompt An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language. 
 */


data class RealtimeSessionCreateRequestInputAudioTranscription (

    /* The model to use for transcription, `whisper-1` is the only currently  supported model.  */
    @Json(name = "model")
    val model: RealtimeSessionCreateRequestInputAudioTranscription.Model? = null,

    /* The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format will improve accuracy and latency.  */
    @Json(name = "language")
    val language: kotlin.String? = null,

    /* An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.  */
    @Json(name = "prompt")
    val prompt: kotlin.String? = null

) {

    /**
     * The model to use for transcription, `whisper-1` is the only currently  supported model.
     *
     * Values: whisper-1
     */
    @JsonClass(generateAdapter = false)
    enum class Model(val value: kotlin.String) {
        @Json(name = "whisper-1") whisperDash1("whisper-1"),
    }

}

